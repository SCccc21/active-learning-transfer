# -*- coding: utf-8 -*-
"""cifar2stsl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ndowz7Z2oJ7gIUtr0Cw8r9GOu5y3F4Pf

# Import Libraries
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import torch.nn.functional as F
from torch.optim.lr_scheduler import StepLR, MultiStepLR

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

import keras
from keras.layers import Input, Flatten, Dense, LeakyReLU, Dropout
from keras.models import Sequential
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers.core import Activation, Flatten, Dense
from keras import backend as K
from keras.models import clone_model
from keras import Model
from keras.datasets import mnist
from keras.utils import np_utils

import tensorflow.compat.v1 as tf
from tensorflow.keras import regularizers
from tensorflow.keras import initializers

import numpy as np
import collections
import copy
import pandas as pd 
import matplotlib.pyplot as plt 
import scipy.optimize as op 
import seaborn as sns
import pickle


import torchvision.datasets as datasets
import torchvision
import torchvision.transforms as transforms


"""### FASS"""

class PyTorchFlatten(nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)

class LogisticRegression(torch.nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LogisticRegression, self).__init__()
        self.flatten = PyTorchFlatten()
        self.linear = torch.nn.Linear(input_dim, output_dim)
        torch.nn.init.xavier_uniform(self.linear.weight)
        torch.nn.init.zeros_(self.linear.bias)

    def forward(self, x, last=False):
        x = self.flatten(x)
        outputs = self.linear(x)
        if last:
            return outputs, x
        else:
            return outputs

    def get_embedding_dim(self):
        return 28*28


class MnistLeNet(torch.nn.Module):
    def __init__(self):
        super(MnistLeNet, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding_mode='replicate')
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.linear1 = nn.Linear(in_features=2880, out_features=500)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(in_features=500, out_features=10)

        torch.nn.init.xavier_uniform(self.conv1.weight)
        torch.nn.init.zeros_(self.conv1.bias)

        torch.nn.init.xavier_uniform(self.linear1.weight)
        torch.nn.init.zeros_(self.linear1.bias)

        torch.nn.init.xavier_uniform(self.linear2.weight)
        torch.nn.init.zeros_(self.linear2.bias)

    def forward(self, x, last=False):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = torch.flatten(x, 1)
        x = self.relu(self.linear1(x))
        logits = self.linear2(x)
        outputs = F.softmax(logits, dim=1)

        if last:
            return outputs, x
        else:
            return outputs

    def get_embedding_dim(self):
        return 500

from torch.utils.data import Dataset, DataLoader, TensorDataset

def torch_mnist_logistic_data_to_acc(x_train, y_train, verbose=0):

  criterion = torch.nn.CrossEntropyLoss()
  net = LogisticRegression(28*28, 10)
  optimizer = torch.optim.Adam(net.parameters(), lr=0.001, eps=1e-7)

  tensor_x, tensor_y = torch.Tensor(x_train), torch.Tensor(y_train)
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=32, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test), torch.Tensor(y_test)
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(5):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images.view(-1, 28 * 28))
          labels = Variable(labels)
          labels = torch.argmax(labels, dim=1)
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          images = Variable(images.view(-1, 28*28))
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          labels = torch.argmax(labels, dim=1)
          correct += (predicted == labels).sum()
      accuracy = 100 * correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  print('Model Accuracy: {}'.format(accuracy))
  return net

"""## Add Gaussian Noise"""
def addGaussianNoise(x_train, scale=1):
  return np.clip(x_train+np.random.normal(scale=scale, size=x_train.shape), 0, 1)


"""## Image Preprocess

### CIFAR
"""

def cifar_encoderProcess(x_train, y_train, x_test, y_test):

  N_train = len(y_train)
  N_test = len(y_test)


  # x_train = x_train.astype(np.float32)
  # x_test = x_test.astype(np.float32)
  # x_train = np.moveaxis(x_train, 1, 3)
  # x_test = np.moveaxis(x_test, 1, 3)

  x_train = torch.from_numpy(x_train)
  x_test = torch.from_numpy(x_test) # tensor of shape 3, 32, 32
  
  x_transfer = transforms.Compose([
                      transforms.ToPILImage(), #Tensor of shape C x H x W or a numpy ndarray of shape H x W x C
                      transforms.ToTensor(),
                      # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2430, 0.2610))
                      ])

  x_train_r = []
  for i in range(x_train.shape[0]):
    # import pdb; pdb.set_trace()
    x_r = x_transfer(x_train[i])
    x_train_r.append(x_r)

  b = torch.Tensor(N_train, 3, 32, 32)
  x_train_r = torch.cat(x_train_r, out=b)
  x_train_r = x_train_r.reshape(N_train, 3, 32, 32)

  x_test_r = []
  for i in range(x_test.shape[0]):
    x_r = x_transfer(x_test[i])
    x_test_r.append(x_r)

  b = torch.Tensor(N_test, 3, 32, 32)
  x_test_r = torch.cat(x_test_r, out=b)
  x_test_r = x_test_r.reshape(N_test, 3, 32, 32)

  y_train = torch.Tensor(y_train).long()
  y_test = torch.Tensor(y_test).long()

  return x_train_r, y_train, x_test_r, y_test

"""### CIFAR data to acc"""

import torchvision.datasets as datasets
import torchvision
import torchvision.transforms as transforms

class SmallCNN_CIFAR(nn.Module):
    def __init__(self):
        super(SmallCNN_CIFAR, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x, last=False):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        feat = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(feat))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        if last:
          return x, feat
        else:
          return x

    def getFeature(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        return x

    def get_embedding_dim(self):
        return 16 * 5 * 5



class LargeCNN(nn.Module):

    def __init__(self):
        super(LargeCNN, self).__init__()

        self.conv_layer = nn.Sequential(

            # Conv Layer block 1
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            # Conv Layer block 2
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout2d(p=0.05),

            # Conv Layer block 3
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )


        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(4096, 1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(512, 10)
        )


    def forward(self, x):
        """Perform forward."""
        
        # conv layers
        x = self.conv_layer(x)
        
        # flatten
        x = x.view(x.size(0), -1)
        
        # fc layer
        x = self.fc_layer(x)

        return x

def torch_cifar_logistic_data_to_acc(x_train, y_train, x_test, y_test, verbose=0):

  criterion = torch.nn.CrossEntropyLoss()
  net = SmallCNN_CIFAR().cuda()
  optimizer = torch.optim.Adam(net.parameters(), lr=0.001, eps=1e-7)

  tensor_x, tensor_y = torch.Tensor(x_train).cuda(), torch.Tensor(y_train).cuda()
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=32, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test).cuda(), torch.Tensor(y_test).cuda()
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(10):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images)
          labels = Variable(labels).long()
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          images = Variable(images)
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum()
      accuracy = 100 * correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  return accuracy.item()


def torch_cifar_logistic_data_to_net(x_train, y_train, x_test, y_test, n_epoch=10, verbose=0):

  criterion = torch.nn.CrossEntropyLoss()
  net = SmallCNN_CIFAR().cuda()
  optimizer = torch.optim.Adam(net.parameters(), lr=0.001, eps=1e-7)

  tensor_x, tensor_y = torch.Tensor(x_train).cuda(), torch.Tensor(y_train).cuda()
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=32, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test).cuda(), torch.Tensor(y_test).cuda()
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(n_epoch):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images)
          labels = Variable(labels).long()
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          images = Variable(images)
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum()
      accuracy = 100 * correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  return net


def torch_cifar_logistic_data_to_acc_multiple(X_train, y_train, x_test, y_test, repeat=3, verbose=0):
  acc_lst = []
  for _ in range(repeat):
    acc = torch_cifar_logistic_data_to_acc(X_train, y_train, x_test, y_test, verbose)
    acc_lst.append(acc)
  return np.mean(acc_lst)




def torch_cifar_cnn_data_to_acc(x_train, y_train, verbose=0):

  criterion = torch.nn.CrossEntropyLoss()
  net = LargeCNN().cuda()
  optimizer = torch.optim.Adam(net.parameters(), lr=0.001, eps=1e-7)

  tensor_x, tensor_y = torch.Tensor(x_train).cuda(), torch.Tensor(y_train).cuda()
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=32, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test).cuda(), torch.Tensor(y_test).cuda()
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(20):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images)
          labels = Variable(labels).long()
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          images = Variable(images)
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum()
      accuracy = 100 * correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  return accuracy.item()


def torch_cifar_cnn_data_to_acc_multiple(X_train, y_train, repeat=3, verbose=0):
  acc_lst = []
  for _ in range(repeat):
    acc = torch_cifar_cnn_data_to_acc(X_train, y_train, verbose)
    acc_lst.append(acc)
  return np.mean(acc_lst)

"""### STL"""

def stl_encoderProcess(x_train, y_train, x_test, y_test):

  N_train = len(y_train)
  N_test = len(y_test)


  # x_train = x_train.astype(np.float32)
  # x_test = x_test.astype(np.float32)
  # x_train = np.moveaxis(x_train, 1, 3)
  # x_test = np.moveaxis(x_test, 1, 3)

  x_train = torch.from_numpy(x_train)
  x_test = torch.from_numpy(x_test) # tensor of shape 3, 96, 96
  
  x_transfer = transforms.Compose([
                      transforms.ToPILImage(), #Tensor of shape C x H x W or a numpy ndarray of shape H x W x C
                      transforms.Resize(32),
                      transforms.ToTensor(),
                      # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                      transforms.Normalize((0.4467, 0.4398, 0.4066), (0.2603, 0.2565, 0.2712))
                      ])

  x_train_r = []
  for i in range(x_train.shape[0]):
    # import pdb; pdb.set_trace()
    x_r = x_transfer(x_train[i])
    x_train_r.append(x_r)

  b = torch.Tensor(N_train, 3, 32, 32)
  x_train_r = torch.cat(x_train_r, out=b)
  x_train_r = x_train_r.reshape(N_train, 3, 32, 32)

  x_test_r = []
  for i in range(x_test.shape[0]):
    x_r = x_transfer(x_test[i])
    x_test_r.append(x_r)

  b = torch.Tensor(N_test, 3, 32, 32)
  x_test_r = torch.cat(x_test_r, out=b)
  x_test_r = x_test_r.reshape(N_test, 3, 32, 32)

  y_train = torch.Tensor(y_train).long()
  y_test = torch.Tensor(y_test).long()

  return x_train_r, y_train, x_test_r, y_test

"""### STL data to acc"""

#NOTE: y_train should be one-hot vector


class SmallCnnSTL(nn.Module):
    def __init__(self):
        super(SmallCnnSTL, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 12, 5)
        self.fc1 = nn.Linear(12 * 441, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 12 * 441)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def getFeature(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1)
        return x


from torch.utils.data import Dataset, DataLoader, TensorDataset

def torch_stl_smallcnn_data_to_acc(x_train, y_train, x_test, y_test, verbose=0):

  if x_train.shape[1]==96:
    x_train = np.moveaxis(x_train, 3, 1)
    x_test = np.moveaxis(x_test, 3, 1)

  y_train = y_train.reshape(-1)
  y_test = y_test.reshape(-1)

  criterion = torch.nn.CrossEntropyLoss()
  net = SmallCnnSTL().cuda()
  optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, eps=1e-7)

  # import pdb;pdb.set_trace()
  tensor_x, tensor_y = torch.Tensor(x_train).cuda(), torch.Tensor(y_train).cuda()
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=16, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test).cuda(), torch.Tensor(y_test).cuda()
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(30):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images)
          labels = Variable(labels).long()
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          images = Variable(images)
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum()
      accuracy = correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  return accuracy.item()


def torch_stl_smallcnn_data_to_acc_multiple(x_train, y_train, x_val, y_val, repeat=3, verbose=0):
  acc_lst = []
  for _ in range(repeat):
    acc = torch_stl_smallcnn_data_to_acc(x_train, y_train, x_val, y_val, verbose)
    acc_lst.append(acc)
  return np.mean(acc_lst)

"""## ResNetCifar"""

# Based on the ResNet implementation in torchvision
# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py

import math
import torch
from torch import nn
from torchvision.models.resnet import conv3x3

class BasicBlock(nn.Module):
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.downsample = downsample
        self.stride = stride
        
        self.bn1 = nn.BatchNorm2d(inplanes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(inplanes, planes, stride)
        
        self.bn2 = nn.BatchNorm2d(planes)
        self.relu2 = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        residual = x 
        residual = self.bn1(residual)
        residual = self.relu1(residual)
        residual = self.conv1(residual)

        residual = self.bn2(residual)
        residual = self.relu2(residual)
        residual = self.conv2(residual)

        if self.downsample is not None:
            x = self.downsample(x)
        return x + residual

class Downsample(nn.Module):
    def __init__(self, nIn, nOut, stride):
        super(Downsample, self).__init__()
        self.avg = nn.AvgPool2d(stride)
        assert nOut % nIn == 0
        self.expand_ratio = nOut // nIn

    def forward(self, x):
        x = self.avg(x)
        return torch.cat([x] + [x.mul(0)] * (self.expand_ratio - 1), 1)

class ResNetCifar(nn.Module):
    def __init__(self, depth, width=1, block=BasicBlock, classes=10, channels=3):
        assert (depth - 2) % 6 == 0
        self.N = (depth - 2) // 6
        super(ResNetCifar, self).__init__()

        # Following the Wide ResNet convention, we fix the very first convolution
        self.conv1 = nn.Conv2d(channels, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.inplanes = 16
        self.layer1 = self._make_layer(block, 16 * width)
        self.layer2 = self._make_layer(block, 32 * width, stride=2)
        self.layer3 = self._make_layer(block, 64 * width, stride=2)
        self.bn = nn.BatchNorm2d(64 * width)
        self.relu = nn.ReLU(inplace=True)
        self.avgpool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64 * width, classes)

        # Initialization
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
                
    def _make_layer(self, block, planes, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes:
            downsample = Downsample(self.inplanes, planes, stride)
        layers = [block(self.inplanes, planes, stride, downsample=downsample)]
        self.inplanes = planes
        for i in range(self.N - 1):
            layers.append(block(self.inplanes, planes))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.bn(x)
        x = self.relu(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x




"""### Extract feature (cycada)"""

def featureExtract_cycda(x, ext):
  assert list(x.shape[1:]) == [1, ext.image_size, ext.image_size]
  score, out = ext(x.cuda(), with_ft=True)
  return out.view(out.size(0), -1)

"""### Extract feature (ResNet)"""

def extractor_from_layer3(net):
    layers = [net.conv1, net.layer1, net.layer2, net.layer3, net.bn, net.relu, net.avgpool]
    return nn.Sequential(*layers)
 
def featureExtract(x, ext):
    assert list(x.shape[1:]) == [3, 32, 32]
    
    batch_size = 64
    train_size = x.size(0)
    x_feat = torch.zeros(train_size, 128)
    x = x.float().cuda()

    with torch.no_grad():
        for j in range(train_size//batch_size):
            start_ind = j*batch_size
            x_f = ext(x[start_ind: min(start_ind+batch_size, train_size)])
            # import pdb; pdb.set_trace()
            x_f = x_f.view(x_f.size(0), -1)
            # x_feat.append(x_f)
            x_feat[start_ind: min(start_ind+batch_size, train_size)] = x_f

    # b = torch.Tensor(train_size, x_f.shape[1])
    # x_feat = torch.cat(x_feat, out=b)
    return x_feat.detach().cpu().numpy()




"""### Baselines"""

from torch.utils.data import Dataset, DataLoader, TensorDataset

class torchLogisticRegression(torch.nn.Module):
    def __init__(self, input_dim, output_dim):
        super(torchLogisticRegression, self).__init__()
        self.flatten = Flatten()
        self.linear = torch.nn.Linear(input_dim, output_dim)
        torch.nn.init.xavier_uniform(self.linear.weight)
        torch.nn.init.zeros_(self.linear.bias)
        self.input_dim = input_dim

    def forward(self, x, last=False):
        outputs = self.linear(x)
        if last:
            return outputs, x
        else:
            return outputs

    def get_embedding_dim(self):
        return self.input_dim


def torch_encoder_logistic_data_to_net(x_train, y_train, x_test, y_test, verbose=0):

  criterion = torch.nn.CrossEntropyLoss()
  net = torchLogisticRegression(x_train.shape[1], 10)
  optimizer = torch.optim.Adam(net.parameters(), lr=0.001, eps=1e-7)

  tensor_x, tensor_y = torch.Tensor(x_train), torch.Tensor(y_train)
  fewshot_dataset = TensorDataset(tensor_x,tensor_y)
  train_loader = DataLoader(dataset=fewshot_dataset, batch_size=32, shuffle=True)
  tensor_x_test, tensor_y_test = torch.Tensor(x_test), torch.Tensor(y_test)
  test_dataset = TensorDataset(tensor_x_test,tensor_y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  for epoch in range(5):
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images)
          labels = Variable(labels.long())
        #   labels = torch.argmax(labels, dim=1)
          optimizer.zero_grad()
          outputs = net(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      for images, labels in test_loader:
          labels = labels.long()
          images = Variable(images)
          outputs = net(images)
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
        #   labels = torch.argmax(labels, dim=1)
          correct += (predicted == labels).sum()
      accuracy = 100 * correct/total
      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), accuracy))
  print('Model Accuracy: {}'.format(accuracy))
  return net


def get_da_acc(net, x_test, y_test):
  net.eval()

  test_dataset = TensorDataset(x_test,y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  correct = 0
  total = 0
  for images, labels in test_loader:
      images = Variable(images.cuda(), requires_grad=False)
      labels = Variable(labels.cuda(), requires_grad=False)
      score = net(images)
      pred = score.data.max(1)[1] # get the index of the max log-probability
      correct += pred.eq(labels.data).cpu().sum()
      total += labels.size(0)
      
  accuracy = 100.0 * correct/total
  return accuracy / 100


def FeatExtractCPU(net, x):
  with torch.no_grad():
    feat = extractor_from_layer3(net)(x.cuda())
    # out = ext(x.float().cuda())
    feat = feat.view(feat.size(0), -1)
  return feat

# def FeatExtractCPU(net, x):
#   feat = extractor_from_layer3(net.cpu())(x.cpu())
#   feat = feat.view(feat.size(0), -1)
#   net.cuda()
#   return feat.cuda()

def setTrainFalse(layer):
  for i in range(4):
    layer[i].conv1.weight.trainable = False
    layer[i].conv2.weight.trainable = False



from scipy.stats import wasserstein_distance
def get_label(centroids, feat):
  best_dist = 1e9
  for k in range(len(centroids)):
    # import pdb;pdb.set_trace()
    dist = wasserstein_distance(centroids[k].detach().cpu(), feat.detach().cpu())
    if dist < best_dist:
      best_dist = dist 
      pred_label = k 
  
  return pred_label


def data_to_acc_finetune_normal(adda_net_file, x_train, y_train, x_test, y_test, verbose=0, lr=2e-6):
  net = ResNetCifar(26, 2, classes=10, channels=3).cuda()
  net.load_state_dict(torch.load(adda_net_file))
  net.train()

  net.conv1.weight.trainable = False
  setTrainFalse(net.layer1)
  setTrainFalse(net.layer2)
  setTrainFalse(net.layer3)
  

  optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0)
  criterion = nn.CrossEntropyLoss()



  finetune_dataset = TensorDataset(x_train,y_train)
  train_loader = DataLoader(dataset=finetune_dataset, batch_size=32, shuffle=True)
  test_dataset = TensorDataset(x_test,y_test)
  test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)

  best_acc = 0
  for epoch in range(35):
      net.train()
      for i, (images, labels) in enumerate(train_loader):
          images = Variable(images.cuda(), requires_grad=False)
          labels = Variable(labels.cuda().long(), requires_grad=False)
          optimizer.zero_grad()
          score = net(images)
          loss = criterion(score, labels)
          loss.backward()
          optimizer.step()
      correct = 0
      total = 0
      test_acc = get_da_acc(net, x_test, y_test)

      if verbose:
        print("Epoch: {}. Loss: {}. Accuracy: {}.".format(epoch, loss.item(), test_acc*100.0))

      if test_acc > best_acc:
        best_acc = test_acc
      else:
        break
  print('Model Accuracy: {}'.format(best_acc*100.0))
  return best_acc


def get_unlabel(selected_rank, stl_x_unlabel_few_re, stl_y_unlabel_few_re):
  idx_unlabel = np.ones_like(stl_y_unlabel_few_re, dtype=bool)
  idx_unlabel[selected_rank] = False
  return stl_x_unlabel_few_re[idx_unlabel]



"""## Multi seed (fine-tune)"""
def check_selection_unnormal(set_selected):
  # input is torch tensor
  for i in range(10):
    if i in set_selected:
      continue
    else:
      return True
  return False



def plot_fill(record, name, col):
  plt.plot(inspect_points, np.mean(record, axis=0), label=name, color=col)
  plt.fill_between(inspect_points, np.mean(record, axis=0)+np.std(record, axis=0), np.mean(record, axis=0)-np.std(record, axis=0), alpha=0.2, color=col)
